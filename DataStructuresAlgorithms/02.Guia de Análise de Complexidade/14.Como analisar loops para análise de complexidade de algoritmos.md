Discutimos Análise Assintótica, Piores, Médios e Melhores Casos e Notações Assintóticas em posts anteriores. Neste post, é discutida uma análise de programas iterativos com exemplos simples.

A análise de loops para a análise de complexidade de algoritmos envolve encontrar o número de operações realizadas por um loop em função do tamanho da entrada. Isso geralmente é feito determinando o número de iterações do loop e o número de operações executadas em cada iteração.

### Aqui estão as etapas gerais para analisar loops para análise de complexidade:

Determine o número de iterações do loop. Isso geralmente é feito analisando as variáveis de controle de loop e a condição de término do loop.

Determine o número de operações executadas em cada iteração do loop. Isso pode incluir operações aritméticas e operações de acesso a dados, como acessos a matriz ou acessos à memória.

Expresse o número total de operações executadas pelo loop em função do tamanho da entrada. Isso pode envolver o uso de expressões matemáticas ou encontrar uma expressão de forma fechada para o número de operações executadas pelo loop.

Determine a ordem de crescimento da expressão para o número de operações executadas pelo loop. Isso pode ser feito usando técnicas como notação O grande ou encontrando o termo dominante e ignorando termos de ordem inferior.

### Complexidade de tempo constante O(1):

A complexidade de tempo de uma função (ou conjunto de instruções) é considerada como O(1) se não contiver um loop, recursão e chamada para qualquer outra função de tempo não constante.
ou seja, conjunto de instruções não recursivas e não loop

Em ciência da computação, O(1) refere-se à complexidade de tempo constante, o que significa que o tempo de execução de um algoritmo permanece constante e não depende do tamanho da entrada. Isso significa que o tempo de execução de um algoritmo O(1) sempre levará a mesma quantidade de tempo, independentemente do tamanho da entrada. Um exemplo de um algoritmo O(1) é acessar um elemento em uma matriz usando um índice.

### Exemplo: 

swap() tem complexidade de tempo O(1).
Um loop ou recursão que é executado um número constante de vezes também é considerado O(1). Por exemplo, o loop a seguir é O(1).

```
// Here c is a constant
for (var i = 1; i <= c; i++) {
    // some O(1) expressions
}
```

### Complexidade de tempo linear O(n):

A complexidade de tempo de um loop é considerada como O(n) se as variáveis de loop forem incrementadas/diminuídas por uma quantidade constante. Por exemplo, as funções a seguir têm complexidade de tempo O(n). A complexidade de tempo linear, denotada como O(n), é uma medida do crescimento do tempo de execução de um algoritmo proporcional ao tamanho da entrada. Em um algoritmo O(n), o tempo de execução aumenta linearmente com o tamanho da entrada. Por exemplo, pesquisar um elemento em uma matriz não classificada ou iterar por meio de uma matriz e executar uma quantidade constante de trabalho para cada elemento seriam operações O(n). Em palavras simples, para uma entrada de tamanho n, o algoritmo executa n etapas para concluir a operação.

```
// Here c is a positive integer constant
for (var i = 1; i <= n; i += c) {
    // some O(1) expressions
}

for (var i = n; i > 0; i -= c) {
    // some O(1) expressions
}
```

### Complexidade de tempo quadrática O(nc):

A complexidade de tempo é definida como um algoritmo cujo desempenho é diretamente proporcional ao tamanho quadrado dos dados de entrada, pois em loops aninhados é igual ao número de vezes que a instrução mais interna é executada. Por exemplo, os seguintes loops de amostra têm O(n2) complexidade de tempo

A complexidade de tempo quadrática, denotada como O(n^2), refere-se a um algoritmo cujo tempo de execução aumenta proporcionalmente ao quadrado do tamanho da entrada. Em outras palavras, para uma entrada de tamanho n, o algoritmo executa n * n etapas para concluir a operação. Um exemplo de um algoritmo O(n^2) é um loop aninhado que itera em toda a entrada para cada elemento, executando uma quantidade constante de trabalho para cada iteração. Isso resulta em um total de n * n iterações, tornando o tempo de execução quadrático no tamanho da entrada.

```
for (var i = 1; i <= n; i += c) {
    for (var j = 1; j <= n; j += c) {
        // some O(1) expressions
    }
}

for (var i = n; i > 0; i -= c) {
    for (var j = i + 1; j <= n; j += c) {
        // some O(1) expressions
    }
 }
```

Exemplo: Selection sort e Insertion Sort têm O(n2) complexidade temporal.

### Complexidade de tempo logarítmico O(Log n):

A complexidade de tempo de um loop é considerada como O(Logn) se as variáveis do loop forem divididas/multiplicadas por uma quantidade constante. E também para chamadas recursivas na função recursiva, a Complexidade de Tempo é considerada como O(Logn).

```
for (var i = 1; i <= n; i *= c) {
    // some O(1) expressions
}
for (var i = n; i > 0; i /= c) {
    // some O(1) expressions
}
```

```
// Recursive function
function recurse(n)
{
    if (n <= 0)
        return;
    else {
        // some O(1) expressions
    }
    recurse(n/c);
 // Here c is positive integer constant greater than 1
}
```

Exemplo: Pesquisa binária (consulte implementação iterativa) tem complexidade de tempo O(Logn).

### Complexidade de tempo logarítmico O(Log Log n):

A complexidade de tempo de um loop é considerada como O(LogLogn) se as variáveis de loop forem reduzidas/aumentadas exponencialmente por uma quantidade constante.

```
// Here c is a constant greater than 1
for (var i = 2; i <= n; i = i**c) {
    // some O(1) expressions
}
// Here fun is sqrt or cuberoot or any other constant root
for (var i = n; i > 1; i = fun(i)) {
    // some O(1) expressions
}
```

Veja isso para detalhes matemáticos.

### Como combinar as complexidades de tempo de loops consecutivos? 

Quando há loops consecutivos, calculamos a complexidade de tempo como uma soma das complexidades de tempo de loops individuais.

Para combinar as complexidades de tempo de loops consecutivos, você precisa considerar o número de iterações executadas por cada loop e a quantidade de trabalho executado em cada iteração. A complexidade de tempo total do algoritmo pode ser calculada multiplicando o número de iterações de cada loop pela complexidade de tempo de cada iteração e tomando o máximo de todas as combinações possíveis.

Por exemplo, considere o seguinte código:

```
for i in range(n):  
  for j in range(m):  
    # some constant time operation
```

Aqui, o loop externo executa n iterações e o loop interno executa m iterações para cada iteração do loop externo. Portanto, o número total de iterações executadas pelo loop interno é n * m e a complexidade total do tempo é O(n * m).

Em outro exemplo, considere o seguinte código:

```
for i in range(n):  
  for j in range(i):  
    # some constant time operation
```

Aqui, o loop externo executa n iterações e o loop interno executa i iterações para cada iteração do loop externo, onde i é a contagem de iterações atual do loop externo. O número total de iterações realizadas pelo loop interno pode ser calculado somando o número de iterações realizadas em cada iteração do loop externo, que é dado pela fórmula sum(i) de i=1 a n, que é igual a n * (n + 1) / 2. Portanto, o tempo total complexo

```
for (var i = 1; i <= m; i += c) {
    // some O(1) expressions
}
for (var i = 1; i <= n; i += c) {
    // some O(1) expressions
}

// Time complexity of above code is O(m) + O(n) which is O(m + n) 
// If m == n, the time complexity becomes O(2n) which is O(n).
```

### Como calcular a complexidade do tempo quando há muitas instruções if, else dentro de loops? 

Conforme discutido aqui, a complexidade de tempo do pior caso é a mais útil entre os melhores, médios e piores. Portanto, precisamos considerar o pior caso. Avaliamos a situação em que os valores em condições if-else fazem com que um número máximo de instruções seja executado.
Por exemplo, considere a função de pesquisa linear em que consideramos o caso em que um elemento está presente no final ou não está presente.
Quando o código é muito complexo para considerar todos os casos if-else, podemos obter um limite superior ignorando if-else e outras instruções de controle complexas.

### Como calcular a complexidade temporal das funções recursivas? 

A complexidade temporal de uma função recursiva pode ser escrita como uma relação de recorrência matemática. Para calcular a complexidade do tempo, devemos saber como resolver as recorrências. Em breve, discutiremos técnicas de resolução de recorrência como um post separado.

### Folha de dicas de algoritmos:

|Algorithm|Best Case|Average Case|Worst Case|
|---|---|---|---|
|Selection Sort|O(n^2)|O(n^2)|O(n^2)|
|Bubble Sort|O(n)|O(n^2)|O(n^2)|
|Insertion Sort|O(n)|O(n^2)|O(n^2)|
|Tree Sort|O(nlogn)|O(nlogn)|O(n^2)|
|Radix Sort|O(dn)|O(dn)|O(dn)|
|Merge Sort|O(nlogn)|O(nlogn)|O(nlogn)|
|Heap Sort|O(nlogn)|O(nlogn)|O(nlogn)|
|Quick Sort|O(nlogn)|O(nlogn)|O(n^2)|
|Bucket Sort|O(n+k)|O(n+k)|O(n^2)|
|Counting Sort|O(n+k)|O(n+k)|O(n+k)|

Quiz sobre Análise de Algoritmos
Para mais detalhes, consulte: Design e Análise de Algoritmos.

Por favor, escreva comentários se você encontrar algo incorreto, ou se quiser compartilhar mais informações sobre o tópico discutido acima.

