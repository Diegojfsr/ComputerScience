A análise da complexidade de uma relação de recorrência envolve encontrar o limite superior assintótico no tempo de execução de um algoritmo recursivo. Isso geralmente é feito localizando uma expressão de forma fechada para o número de operações executadas pelo algoritmo em função do tamanho da entrada e, em seguida, determinando a ordem de crescimento da expressão à medida que o tamanho da entrada se torna grande.

Aqui estão as etapas gerais para analisar a complexidade de uma relação de recorrência:

Substitua o tamanho da entrada na relação de recorrência para obter uma sequência de termos.

Identifique um padrão na sequência de termos, se houver, e simplifique a relação de recorrência para obter uma expressão de forma fechada para o número de operações executadas pelo algoritmo.

Determine a ordem de crescimento da expressão de forma fechada usando técnicas como o Teorema Mestre, ou encontrando o termo dominante e ignorando os termos de ordem inferior.

Use a ordem de crescimento para determinar o limite superior assintótico no tempo de execução do algoritmo, que pode ser expresso em termos de notação de O grande.

É importante observar que as etapas acima são apenas um esboço geral e que os detalhes específicos de como analisar a complexidade de uma relação de recorrência podem variar muito, dependendo da relação de recorrência específica que está sendo analisada.

No post anterior, discutimos a análise de loops. Muitos algoritmos são recursivos. Quando os analisamos, obtemos uma relação de recorrência para a complexidade do tempo. Obtemos o tempo de execução em uma entrada de tamanho n em função de n e o tempo de execução em entradas de tamanhos menores. Por exemplo, em Merge Sort, para classificar uma determinada matriz, nós a dividimos em duas metades e repetimos recursivamente o processo para as duas metades. Por fim, mesclamos os resultados. A complexidade de tempo do Merge Sort pode ser escrita como T(n) = 2T(n/2) + cn. Existem muitos outros algoritmos como Binary Search, Tower of Hanoi, etc.

necessidade de resolver recorrências:
A solução de recorrências é importante porque fornece informações sobre o tempo de execução de um algoritmo recursivo. Ao resolver uma recorrência, podemos determinar o limite superior assintótico no número de operações realizadas pelo algoritmo, o que é crucial para avaliar a eficiência e a escalabilidade do algoritmo.

Aqui estão alguns dos motivos para resolver as recorrências:

Análise de algoritmo: Resolver uma recorrência é uma etapa importante na análise da complexidade de tempo de um algoritmo recursivo. Essas informações podem ser usadas para determinar o melhor algoritmo para um problema específico ou para otimizar um algoritmo existente.

Comparação de desempenho: Ao resolver as recorrências, é possível comparar os tempos de execução de diferentes algoritmos, o que pode ser útil na seleção do melhor algoritmo para um determinado caso de uso.

Optimização: Ao entender o tempo de execução de um algoritmo, é possível identificar gargalos e fazer otimizações para melhorar o desempenho do algoritmo.

Investigação: Resolver recorrências é uma parte essencial da pesquisa em ciência da computação, pois ajuda a entender o comportamento dos algoritmos e a desenvolver novos algoritmos.

No geral, a resolução de recorrências desempenha um papel crucial na análise, design e otimização de algoritmos e é um tópico importante na ciência da computação.
Existem basicamente três maneiras de resolver recorrências:

### Método de substituição:

Fazemos um palpite para a solução e, em seguida, usamos a indução matemática para provar que o palpite está correto ou incorreto.

Por exemplo, considere a recorrência $T(n) = 2T(n/2) + n$
Adivinhamos a solução como $T(n) = O(nLogn)$. Agora usamos a indução para provar nosso palpite.
Precisamos provar que $T (n) < = cnLogn$. Podemos supor que é verdade para valores menores que n.

$T(n) = 2T(n/2) + n$  
     $<= 2cn/2Log(n/2) + n$  
       $=  cnLogn - cnLog2 + n$  
       $=  cnLogn - cn + n$  
    $<= cnLogn$

### Método da árvore de recorrência:

Neste método, desenhamos uma árvore de recorrência e calculamos o tempo gasto por cada nível da árvore. Por fim, somamos o trabalho realizado em todos os níveis. Para desenhar a árvore de recorrência, começamos a partir da recorrência dada e continuamos desenhando até encontrarmos um padrão entre os níveis. O padrão é tipicamente aritmético ou geométrico

Por exemplo, considere a relação de recorrência
$T(n) = T(n/4) + T(n/2) + cn²$

       $cn²$
      $/    \$
  $T(n/4)  T(n/2)$

Se dividirmos ainda mais a expressão T(n/4) e T(n/2), obteremos a seguinte árvore de recursão.

       $Cn²$
      $/      \$
  $c(n²)/16  c(n²)/4$
 $/       \      /       \$
$T(n/16)  T(n/8)  T(n/8)  T(n/4)$

Quebrar ainda mais nos dá o seguinte

       $Cn²$
      $/        \$
  $c(n²)/16    c(n²)/4$
 $/       \      /       \$
$c(n²)/256  c(n²)/64  c(n²)/64  c(n²)/16$
 $/    \        /    \      /    \      /    \$

Para saber o valor de T(n), precisamos calcular a soma dos nós da árvore nível por nível. Se somarmos a árvore acima nível por nível, 

obtemos a seguinte série $T(n) = c(n^2 + 5(n^2)/16 + 25(n^2)/256) + ....$ 
A série acima é uma progressão geométrica com uma proporção de 5/16.

Para obter um limite superior, podemos somar a série infinita. Obtemos a soma como (n2)/(1 - 5/16) que é O(n2)


### Método mestre: 

O Método Mestre é uma maneira direta de obter a solução. O método mestre funciona apenas para o seguinte tipo de recorrências ou para recorrências que podem ser transformadas no tipo a seguir.
$T(n) = aT(n/b) + f(n) onde a >= 1 e b > 1$

Existem os três casos a seguir:
$Se f(n) = O(n^c) onde c < log_b(a), então T(n) = Θ(n^(log_b(a)))$ 
$Se f(n) = Θ(n^c) onde c = log_b(a), então T(n) = Θ(n^c log n)$ 
$Se f(n) = Θ(n^c) onde c > log_b(a), então T(n) = Θ(f(n))$

### Como isso funciona? 

O método mestre é derivado principalmente do método da árvore de recorrência. Se desenharmos a árvore de recorrência de $T(n) = aT(n/b) + f(n)$, podemos ver que o trabalho feito na raiz é f(n), e o trabalho feito em todas as folhas é $Θ(n^c)$, onde c é log_b(a). E a altura da árvore de recorrência é log_b(n).

![Master Theorem](https://media.geeksforgeeks.org/wp-content/uploads/AlgoAnalysis.png)

No método da árvore de recorrência, calculamos o trabalho total realizado. Se o trabalho feito nas folhas é polinomialmente maior, então as folhas são a parte dominante, e nosso resultado passa a ser o trabalho feito nas folhas (Caso 1). Se o trabalho realizado nas folhas e na raiz for assintoticamente o mesmo, nosso resultado se torna a altura multiplicada pelo trabalho realizado em qualquer nível (Caso 2). Se o trabalho feito na raiz é assintoticamente maior, então nosso resultado se torna o trabalho feito na raiz (Caso 3).

### Exemplos de alguns algoritmos padrão cuja complexidade de tempo pode ser avaliada usando o Método Mestre

Classificação de mesclagem: T(n) = 2T(n/2) + ? (n). Ele cai no caso 2 como c é 1 e Logba] também é 1. Então a solução é? (n Logn)
Pesquisa binária: T(n) = T(n/2) + ? (1). Também cai no caso 2, pois c é 0 e Logba também é 0. Então a solução é? (Logn)

### Anotações:

Não é necessário que uma recorrência da forma $T(n) = aT(n/b) + f(n)$ possa ser resolvida usando o Teorema Mestre. Os três casos apresentados possuem algumas lacunas entre eles. Por exemplo, a recorrência $T(n) = 2T(n/2) + n/Logn$ não pode ser resolvida usando o método mestre.

O Caso 2 pode ser estendido para $f(n) = Θ(n^c Log^k n)$. Se $f(n) = Θ(n^c Log^k n)$ para alguma constante k >= 0 e c = log_b(a), então $T(n) = Θ(n^c Log^(k+1) n)$.

Para mais detalhes, consulte: Design e Análise de Algoritmos.

